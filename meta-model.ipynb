{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7986bf-3cb2-44e3-b062-b489f94b6a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "from algo_pre_processing import ProjectsData\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd81bbd-8b77-4162-9a9b-5b0d75677902",
   "metadata": {},
   "source": [
    "In the first section, you will load the projects' data. After that, you can proceed to run the statistical feature experiment and the embedding-based features experiment.\n",
    "\n",
    "Since we used 2 batches of data, you will find `embedding_features1` and `embedding_features2` (or `statistical_features1` and `statistical_features2`) representing the two batches we used. However, if you are running an experiment with only one batch of data, you can choose to use only one of them. Simply assign the final dataset (`embedding_features` or `statistical_features`) as the dataset you created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb79f23c-5a8b-4373-b314-d1aa6e6a033c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load projects' data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c78a42-c645-4190-88f1-753c1706b637",
   "metadata": {},
   "source": [
    "Change the following paths according to your implementation:\n",
    "- ProjectsData Object creation:\n",
    "    - `MCW_path`: the results of the label extraction part - the MCW run.\n",
    "    - `projects_path`: the path of the arff files as defined in section 2 of label extraction, you can use either `arff_source` folder or `arff_dest` folder.\n",
    "    - `features_path`: the path of the features you would like to use, for the statistical meta-features we used the output of `statistical meta features.py` and for the embedding based meta-features we used the output of the `embedding java files` folder instructions. \n",
    "    - `algo_matlab_results`: the results of the label extraction part - the MATLAB algorithms output.\n",
    "    - `to_use`: select the folders numbers that you want to use - according to the number of groups defined in `random_groups.py`.\n",
    "- Get data function: use mode for majority voting labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393cc7cf-e323-4498-921d-2de5465b69dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get project's data\n",
    "projects_data = ProjectsData(MCW_path= 'data/MCW/batch1',\n",
    "                 projects_path= 'data/Projects_Arff_batch1',\n",
    "                 features_path= 'meta_model_features/embeddings/graph_embedding.csv',\n",
    "                 algo_matlab_results= 'data/Results_Rest_batch1',\n",
    "                 to_use=list(range(1, 51)))\n",
    "embedding_features1 = projects_data.get_data(label_method='mode')\n",
    "algo_list = projects_data.get_algo_list()\n",
    "algo_scores = projects_data.get_algo_scores()\n",
    "projects_data2 = ProjectsData(MCW_path='data/MCW/batch2',\n",
    "                 projects_path='data/Projects_Arff_batch2',\n",
    "                 features_path= 'meta_model_features/embeddings/graph_embedding.csv',\n",
    "                 algo_matlab_results='data/Results_Rest_batch2',\n",
    "                 to_use=list(range(1, 100)))\n",
    "embedding_features2 = projects_data2.get_data(label_method='mode')\n",
    "\n",
    "embedding_features = pd.concat([embedding_features1,embedding_features2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f4a291-a26d-417d-a248-61cacbbcc478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get project's data\n",
    "projects_data = ProjectsData(MCW_path= 'data/MCW/batch1',\n",
    "                 projects_path= 'data/Projects_Arff_batch1',\n",
    "                 features_path= 'meta_model_features/embeddings/first_batch/base_buggy.csv',\n",
    "                 algo_matlab_results= 'data/Results_Rest_batch1',\n",
    "                 to_use=list(range(1, 51)))\n",
    "code_embedding_features1 = projects_data.get_data(label_method='max')\n",
    "algo_list = projects_data.get_algo_list()\n",
    "algo_scores = projects_data.get_algo_scores()\n",
    "projects_data2 = ProjectsData(MCW_path='data/MCW/batch2',\n",
    "                 projects_path='data/Projects_Arff_batch2',\n",
    "                 features_path= 'meta_model_features/embeddings/second_batch/base_buggy.csv',\n",
    "                 algo_matlab_results='data/Results_Rest_batch2',\n",
    "                 to_use=list(range(1, 100)))\n",
    "code_embedding_features2 = projects_data2.get_data(label_method='max')\n",
    "\n",
    "code_embedding_features = pd.concat([code_embedding_features1,code_embedding_features2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c866b90-4e3f-41d7-b7fa-0b36aaddc4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get project's data\n",
    "projects_data = ProjectsData(MCW_path= 'data/MCW/batch1',\n",
    "                 projects_path= 'data/Projects_Arff_batch1',\n",
    "                 features_path= 'meta_model_features/statistical_features/features_first_batch.csv',\n",
    "                 algo_matlab_results= 'data/Results_Rest_batch1',\n",
    "                            to_use=list(range(1, 51)))\n",
    "statistical_features1 = projects_data.get_data(label_method='max')\n",
    "algo_list = projects_data.get_algo_list()\n",
    "algo_scores = projects_data.get_algo_scores()\n",
    "projects_data2 = ProjectsData(MCW_path='data/MCW/batch2',\n",
    "                 projects_path='data/Projects_Arff_batch2',\n",
    "                 features_path= 'meta_model_features/statistical_features/features_second_batch.csv',\n",
    "                 algo_matlab_results='data/Results_Rest_batch2',\n",
    "                 to_use=list(range(1, 100)))\n",
    "statistical_features2 = projects_data2.get_data(label_method='max')\n",
    "\n",
    "statistical_features = pd.concat([statistical_features1,statistical_features2]) # statistical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f01d08f-672c-45dc-a6d1-16a908f0910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we have the same projects for embedding experiment and statistical experiment\n",
    "pv_embedding = embedding_features[['pv']]\n",
    "pv_embedding.columns = ['pv2']\n",
    "statistical_features = statistical_features.merge(pv_embedding, left_on='pv', right_on='pv2')\n",
    "statistical_features = projects_data.get_mode_value(statistical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fa2c66-9750-4e5d-b592-07d79a0d554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def results_processing(algo_list, joined, y_test, preds):\n",
    "    # get the predictions of the algo + the real label\n",
    "    new_df = pd.DataFrame(y_test)\n",
    "    new_df['prediction'] = preds\n",
    "    with_res = new_df.join(joined, lsuffix=\"l\")\n",
    "    with_res = with_res[['prediction', 'best_algo'] + algo_scores]\n",
    "\n",
    "    for metric in [\"\", \"_precision\", \"_recall\", \"_accuracy\"]:\n",
    "        # get comb results\n",
    "        with_res['comb' + metric] = None\n",
    "        for algo in algo_list:\n",
    "            with_res['comb' + metric].loc[with_res['prediction'] == algo] = \\\n",
    "                with_res[with_res['prediction'] == algo][\n",
    "                    algo + metric]\n",
    "        with_res['comb' + metric] = with_res['comb' + metric].astype(float)\n",
    "\n",
    "    # get best algorithm results\n",
    "    with_res['best'] = None\n",
    "    for algo in algo_list:\n",
    "        with_res['best'].loc[with_res['best_algo'] == algo] = with_res[with_res['best_algo'] == algo][algo]\n",
    "    with_res['best'] = with_res['best'].astype(float)\n",
    "\n",
    "    # get the error for each algo\n",
    "    for algo in algo_list + ['comb']:\n",
    "        with_res[algo + \"_error\"] = (with_res['best'] - with_res[algo]).astype(float)\n",
    "    return with_res\n",
    "random_st = 14\n",
    "\n",
    "grid_dictionary = {'RF': (RandomForestClassifier(random_state=random_st), \n",
    "                          {'n_estimators': [20,50,100,150],\n",
    "                            'max_features': ['sqrt', 'log2'],\n",
    "                            'max_depth': [2,3,4],\n",
    "                            'criterion': ['gini', 'entropy', \"log_loss\"]}),\n",
    "                   'XGboost': (GradientBoostingClassifier(random_state=random_st),\n",
    "                               {\"loss\": [\"deviance\"],\n",
    "                                \"learning_rate\": [0.05,0.1],\n",
    "                                \"min_samples_split\": [0.28,0.4],\n",
    "                                \"min_samples_leaf\": [0.1,0.2],\n",
    "                                \"max_depth\": [2,3,4,5,6],\n",
    "                                \"max_features\": [\"sqrt\"],\n",
    "                                \"criterion\": [\"friedman_mse\",\"mse\"],\n",
    "                                \"subsample\": [0.5,0.8],\n",
    "                                \"n_estimators\": [50,70,100],\n",
    "                                \"warm_start\": [True, False]}),\n",
    "                  'LR': (LogisticRegression(random_state=random_st),\n",
    "                        {\n",
    "                                'penalty' : ['l1','l2'], \n",
    "                                'C'       : np.logspace(-3,3,7),\n",
    "                                'solver'  : ['liblinear'],}),\n",
    "                  'SVM': (SVC(),\n",
    "                                {'C': [0.1, 1, 10, 100, 1000], \n",
    "                                  'gamma': [1, 0.1, 0.01],\n",
    "                                  'kernel': ['rbf']} ),\n",
    "                   'DT':(DecisionTreeClassifier(random_state=0),\n",
    "                               {'criterion': ['gini', 'entropy', \"log_loss\"],\n",
    "                                                           'max_depth': [2,3,4,5,6],\n",
    "                                'min_samples_split':[2,3,4],\n",
    "                                'min_impurity_decrease':[0.01,0.1,0.5]\n",
    "}),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea86656-bf57-4428-a420-78149e6f9d87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CALL-GRAPH Embedding based features experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b130164-496c-41f7-a454-4a2bf611b734",
   "metadata": {},
   "source": [
    "1. Select the meta classifier that will be used: RF-Random Forest, XGboost, LR-Logistic Regression or SVM-Support Vector Machine.\n",
    "2. Select the number of folds for the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b9993-71c9-4663-9913-613392e1a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "META_CLASSIFIER = 'XGboost'\n",
    "NUM_OF_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc49da-d54b-4a70-a331-dca8a54ab597",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_features[['project', 'version']] = embedding_features.pv.str.split(\"_\", expand=True)[[0, 1]]\n",
    "pv_to_keep = pd.read_csv('call_graph_data_sources/pv_above_1000.csv')[['project','version']]\n",
    "embedding_features= embedding_features.merge(pv_to_keep, on=['project','version'])\n",
    "embedding_features = embedding_features.drop(columns=['project',\n",
    " 'version'])                      \n",
    "embedding_features = embedding_features[embedding_features['best_algo'] != 'Dycom']\n",
    "embedding_features = embedding_features[embedding_features['best_algo'] != 'LT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda91c3-625d-4d56-bdaa-388ef8c3ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = embedding_features.drop(columns=['pv'] + algo_scores + ['best_algo','mode_algo'])\n",
    "X = X.fillna(0)\n",
    "y = embedding_features['best_algo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e935dd-81c1-4a2c-8a49-a4a4defe1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "acc_list_embd, f1_list = [], []\n",
    "# split to train and test + oversampling\n",
    "mean_results_embd = {'best':[],'MCW': [], 'MCW_precision': [], 'MCW_recall': [], 'MCW_accuracy': [], 'comb': [], 'comb_precision': [], 'comb_recall': [],\n",
    " 'comb_accuracy': [], 'TPTL': [], 'TPTL_precision': [], 'TPTL_recall': [], 'TPTL_accuracy': [], 'TCA_rnd': [], 'TCA_rnd_precision': [],\n",
    " 'TCA_rnd_recall': [], 'TCA_rnd_accuracy': [], 'LT': [], 'LT_precision': [], 'LT_recall': [], 'LT_accuracy': [], 'Dycom': [], 'Dycom_precision': [],\n",
    " 'Dycom_recall': [], 'Dycom_accuracy': [], 'TDS': [], 'TDS_precision': [], 'TDS_recall': [], 'TDS_accuracy': []}\n",
    "\n",
    "error_results = {'MCW': [], 'comb': [], 'TPTL': [], 'TCA_rnd': [], 'LT': [], 'Dycom': [], 'TDS': []}\n",
    "ss = KFold(n_splits=5,shuffle=True,random_state=14)\n",
    "\n",
    "fold = 0\n",
    "for train_index, test_index in ss.split(X,y):\n",
    "    fold += 1\n",
    "    scaler = StandardScaler()\n",
    "    x_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    print(y_train.value_counts())\n",
    "\n",
    "    x_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "    print(y_test.value_counts())\n",
    "\n",
    "    sm = SMOTE(random_state=random_st, k_neighbors=2)\n",
    "    X_samp, y_samp = sm.fit_resample(x_train, y_train)\n",
    "    print(\"Oversampling is finished....\")\n",
    "    # building the model\n",
    "    rfc = grid_dictionary[META_CLASSIFIER][0]\n",
    "    param_grid = grid_dictionary[META_CLASSIFIER][1]\n",
    "\n",
    "    CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
    "    CV_rfc.fit(X_samp, y_samp)\n",
    "\n",
    "    preds = CV_rfc.best_estimator_.predict(x_test)\n",
    "    print(CV_rfc.best_estimator_)\n",
    "    acc_list_embd.append(accuracy_score(y_test, preds))\n",
    "    f1_list.append(f1_score(y_test, preds, average='micro'))\n",
    "\n",
    "    ####### RESULTS ANALYSIS #######\n",
    "    with_res = results_processing(algo_list, embedding_features, y_test, preds)\n",
    "    \n",
    "    for algo in algo_list +['comb']:\n",
    "        mean_results_embd[algo].append(np.mean(with_res[algo]))\n",
    "        mean_results_embd[algo + \"_precision\"].append(np.mean(with_res[algo + \"_precision\"]))\n",
    "        mean_results_embd[algo + \"_recall\"].append(np.mean(with_res[algo + \"_recall\"]))\n",
    "        mean_results_embd[algo + \"_accuracy\"].append(np.mean(with_res[algo + \"_accuracy\"]))\n",
    "        error_results[algo].append(np.mean(with_res[algo + \"_error\"]))\n",
    "    mean_results_embd['best'].append(np.mean(with_res['best']))\n",
    "    with_res.to_csv(f\"Results_meta_model/current_results/embedding_result_new_data_{fold}.csv\")\n",
    "    \n",
    "print('random_state:', random_st)\n",
    "print(\"MCW f1: \", np.mean(mean_results_embd['MCW']), \", MCW acc: \", np.mean(mean_results_embd['MCW_accuracy']),\n",
    "      \", MCW precision: \", np.mean(mean_results_embd['MCW_precision']), \", MCW recall: \",\n",
    "      np.mean(mean_results_embd['MCW_recall']))\n",
    "print(\"comb f1: \", np.mean(mean_results_embd['comb']), \", comb acc: \", np.mean(mean_results_embd['comb_accuracy']),\n",
    "      \", comb precision: \", np.mean(mean_results_embd['comb_precision']), \", comb recall: \",\n",
    "      np.mean(mean_results_embd['comb_recall']))\n",
    "print(\"best: \", np.mean(mean_results_embd['best']))\n",
    "print(\"accuracy meta model list: \" , acc_list_embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf2578e-3a80-476d-9d11-5029bbbe78fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_unioned = []\n",
    "for i in range(1,6):\n",
    "    temp = pd.read_csv(f'Results_meta_model/current_results/embedding_result_new_data_{i}.csv')\n",
    "    res_unioned.append(temp)\n",
    "res_pd = pd.concat(res_unioned)\n",
    "res_pd.to_csv('exp_call_graph_best_new_data2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777f33ff-7312-406b-b913-bf85d0eba24f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Text Embedding based features experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8e08e-62c0-49af-a1c0-ecde3c7d805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_embedding = embedding_features[['pv']]\n",
    "pv_embedding.columns = ['pv2']\n",
    "code_embedding_features = code_embedding_features.merge(pv_embedding, left_on='pv', right_on='pv2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192e624d-7228-42bf-bb4e-2432125e52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = code_embedding_features.drop(columns=['pv','pv2'] + algo_scores + ['best_algo'])\n",
    "X = X.fillna(0)\n",
    "y = code_embedding_features['best_algo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a9290-1c5a-463a-90e1-4d0e59e76c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_embedding_features.drop_duplicates()['best_algo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a66058-1409-4706-9400-007afeb8a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list_embd, f1_list = [], []\n",
    "# split to train and test + oversampling\n",
    "mean_results_embd = {'best':[],'MCW': [], 'MCW_precision': [], 'MCW_recall': [], 'MCW_accuracy': [], 'comb': [], 'comb_precision': [], 'comb_recall': [],\n",
    " 'comb_accuracy': [], 'TPTL': [], 'TPTL_precision': [], 'TPTL_recall': [], 'TPTL_accuracy': [], 'TCA_rnd': [], 'TCA_rnd_precision': [],\n",
    " 'TCA_rnd_recall': [], 'TCA_rnd_accuracy': [], 'LT': [], 'LT_precision': [], 'LT_recall': [], 'LT_accuracy': [], 'Dycom': [], 'Dycom_precision': [],\n",
    " 'Dycom_recall': [], 'Dycom_accuracy': [], 'TDS': [], 'TDS_precision': [], 'TDS_recall': [], 'TDS_accuracy': []}\n",
    "\n",
    "error_results = {'MCW': [], 'comb': [], 'TPTL': [], 'TCA_rnd': [], 'LT': [], 'Dycom': [], 'TDS': []}\n",
    "ss = KFold(n_splits=5,shuffle=True,random_state=14)\n",
    "\n",
    "fold = 0\n",
    "for train_index, test_index in ss.split(X,y):\n",
    "    fold += 1\n",
    "    scaler = StandardScaler()\n",
    "    x_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    x_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "    sm = SMOTE(random_state=random_st, k_neighbors=2)\n",
    "    X_samp, y_samp = sm.fit_resample(x_train, y_train)\n",
    "    print(\"Oversampling is finished....\")\n",
    "    # building the model\n",
    "    rfc = grid_dictionary[META_CLASSIFIER][0]\n",
    "    param_grid = grid_dictionary[META_CLASSIFIER][1]\n",
    "\n",
    "    CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
    "    CV_rfc.fit(X_samp, y_samp)\n",
    "\n",
    "    preds = CV_rfc.best_estimator_.predict(x_test)\n",
    "    print(CV_rfc.best_estimator_)\n",
    "    acc_list_embd.append(accuracy_score(y_test, preds))\n",
    "    f1_list.append(f1_score(y_test, preds, average='micro'))\n",
    "\n",
    "    ####### RESULTS ANALYSIS #######\n",
    "    with_res = results_processing(algo_list, embedding_features, y_test, preds)\n",
    "    \n",
    "    for algo in algo_list +['comb']:\n",
    "        mean_results_embd[algo].append(np.mean(with_res[algo]))\n",
    "        mean_results_embd[algo + \"_precision\"].append(np.mean(with_res[algo + \"_precision\"]))\n",
    "        mean_results_embd[algo + \"_recall\"].append(np.mean(with_res[algo + \"_recall\"]))\n",
    "        mean_results_embd[algo + \"_accuracy\"].append(np.mean(with_res[algo + \"_accuracy\"]))\n",
    "        error_results[algo].append(np.mean(with_res[algo + \"_error\"]))\n",
    "    mean_results_embd['best'].append(np.mean(with_res['best']))\n",
    "    # results_all = with_res.describe()\n",
    "    with_res.to_csv(f\"Results_meta_model/current_results/text_embedding_result_new_data_{fold}2.csv\")\n",
    "    \n",
    "print('random_state:', random_st)\n",
    "print(\"MCW f1: \", np.mean(mean_results_embd['MCW']), \", MCW acc: \", np.mean(mean_results_embd['MCW_accuracy']),\n",
    "      \", MCW precision: \", np.mean(mean_results_embd['MCW_precision']), \", MCW recall: \",\n",
    "      np.mean(mean_results_embd['MCW_recall']))\n",
    "print(\"comb f1: \", np.mean(mean_results_embd['comb']), \", comb acc: \", np.mean(mean_results_embd['comb_accuracy']),\n",
    "      \", comb precision: \", np.mean(mean_results_embd['comb_precision']), \", comb recall: \",\n",
    "      np.mean(mean_results_embd['comb_recall']))\n",
    "print(\"best: \", np.mean(mean_results_embd['best']))\n",
    "print(\"accuracy meta model list: \" , acc_list_embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fee05a5-353f-4bd3-978d-2ba911ba815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_unioned = []\n",
    "for i in range(1,6):\n",
    "    temp = pd.read_csv(f'Results_meta_model/current_results/text_embedding_result_new_data_{i}2.csv')\n",
    "    res_unioned.append(temp)\n",
    "res_pd = pd.concat(res_unioned)\n",
    "res_pd.to_csv('exp_text_embedding_best_new_data2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6479913e-ee9f-43dc-9485-37d686f4bb38",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Statistical features experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95273a26-aecf-401a-8ad7-d8a0a336df50",
   "metadata": {},
   "source": [
    "1. Select the meta classifier that will be used: RF-Random Forest, XGboost, LR-Logistic Regression or SVM-Support Vector Machine.\n",
    "2. Select the number of folds for the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46deb123-3135-46a8-a58f-4ab0a32208a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "META_CLASSIFIER = 'XGboost'\n",
    "NUM_OF_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807cd9a9-303c-4db4-8e83-605ad971596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_embedding = embedding_features[['pv']]\n",
    "pv_embedding.columns = ['pv2']\n",
    "statistical_features = statistical_features.merge(pv_embedding, left_on='pv', right_on='pv2').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc7db8-3556-42f4-90e2-31b77fa66d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = statistical_features.drop(columns=['pv'] + algo_scores + ['best_algo','Unnamed: 0_std','Unnamed: 0_avg', 'Unnamed: 0_min','Unnamed: 0_skew','mode_algo','pv2_x','pv2_y'])#,'pv2',\n",
    "X = X.fillna(0)\n",
    "y = statistical_features['best_algo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa82e9-06f4-4082-9fd9-300c17c8cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list_stat, f1_list = [], []\n",
    "# split to train and test + oversampling\n",
    "mean_results_stat = {'best':[],'MCW': [], 'MCW_precision': [], 'MCW_recall': [], 'MCW_accuracy': [], 'comb': [], 'comb_precision': [], 'comb_recall': [],\n",
    " 'comb_accuracy': [], 'TPTL': [], 'TPTL_precision': [], 'TPTL_recall': [], 'TPTL_accuracy': [], 'TCA_rnd': [], 'TCA_rnd_precision': [],\n",
    " 'TCA_rnd_recall': [], 'TCA_rnd_accuracy': [], 'LT': [], 'LT_precision': [], 'LT_recall': [], 'LT_accuracy': [], 'Dycom': [], 'Dycom_precision': [],\n",
    " 'Dycom_recall': [], 'Dycom_accuracy': [], 'TDS': [], 'TDS_precision': [], 'TDS_recall': [], 'TDS_accuracy': []}\n",
    "\n",
    "error_results = {'MCW': [], 'comb': [], 'TPTL': [], 'TCA_rnd': [], 'LT': [], 'Dycom': [], 'TDS': []}\n",
    "ss = KFold(n_splits=NUM_OF_FOLDS,shuffle=True,random_state=14)\n",
    "\n",
    "fold = 0\n",
    "for train_index, test_index in ss.split(X,y):\n",
    "    fold += 1\n",
    "    scaler = StandardScaler()\n",
    "    x_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    x_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "    sm = SMOTE(random_state=random_st, k_neighbors=1)\n",
    "    X_samp, y_samp = sm.fit_resample(x_train, y_train)\n",
    "    print(\"Oversampling is finished....\")\n",
    "    # building the model\n",
    "    rfc = grid_dictionary[META_CLASSIFIER][0]\n",
    "    param_grid = grid_dictionary[META_CLASSIFIER][1]\n",
    "\n",
    "    CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
    "    CV_rfc.fit(X_samp, y_samp)\n",
    "\n",
    "    preds = CV_rfc.best_estimator_.predict(x_test)\n",
    "    print(CV_rfc.best_estimator_)\n",
    "    acc_list_stat.append(accuracy_score(y_test, preds))\n",
    "    f1_list.append(f1_score(y_test, preds, average='micro'))\n",
    "\n",
    "    ####### RESULTS ANALYSIS #######\n",
    "    with_res = results_processing(algo_list, statistical_features, y_test, preds)\n",
    "    \n",
    "    for algo in ['MCW', 'comb', 'TPTL', 'TCA_rnd', 'LT', 'Dycom', 'TDS']:\n",
    "        mean_results_stat[algo].append(np.mean(with_res[algo]))\n",
    "        mean_results_stat[algo + \"_precision\"].append(np.mean(with_res[algo + \"_precision\"]))\n",
    "        mean_results_stat[algo + \"_recall\"].append(np.mean(with_res[algo + \"_recall\"]))\n",
    "        mean_results_stat[algo + \"_accuracy\"].append(np.mean(with_res[algo + \"_accuracy\"]))\n",
    "        error_results[algo].append(np.mean(with_res[algo + \"_error\"]))\n",
    "    mean_results_stat['best'].append(np.mean(with_res['best']))\n",
    "    with_res.to_csv(f\"Results_meta_model/current_results/statistical_result_new_data_{fold}.csv\")\n",
    "    \n",
    "print('random_state:', random_st)\n",
    "print(\"MCW f1: \", np.mean(mean_results_stat['MCW']), \", MCW acc: \", np.mean(mean_results_stat['MCW_accuracy']),\n",
    "      \", MCW precision: \", np.mean(mean_results_stat['MCW_precision']), \", MCW recall: \",\n",
    "      np.mean(mean_results_stat['MCW_recall']))\n",
    "print(\"comb f1: \", np.mean(mean_results_stat['comb']), \", comb acc: \", np.mean(mean_results_stat['comb_accuracy']),\n",
    "      \", comb precision: \", np.mean(mean_results_stat['comb_precision']), \", comb recall: \",\n",
    "      np.mean(mean_results_stat['comb_recall']))\n",
    "print(\"best: \", np.mean(mean_results_stat['best']))\n",
    "print(\"accuracy meta model list: \" , acc_list_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78ba5c4-401e-4b42-b6e6-da0921211de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_unioned = []\n",
    "for i in range(1,6):\n",
    "    temp = pd.read_csv(f'Results_meta_model/current_results/statistical_result_new_data_{i}.csv')\n",
    "    res_unioned.append(temp)\n",
    "res_pd = pd.concat(res_unioned)\n",
    "res_pd.to_csv('exp_statistical_best_new_data2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
